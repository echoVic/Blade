# ğŸ“– Blade API å‚è€ƒ

## ğŸ¯ æ ¸å¿ƒç±»

### `Agent` - æ™ºèƒ½ä»£ç†å…¥å£

```typescript
import { Agent } from 'blade-ai';

// åˆ›å»ºAgentå®ä¾‹
const agent = new Agent({
  apiKey: 'sk-xxx',
  baseUrl: 'https://api.example.com',
  modelName: 'my-model'
});

// åŸºç¡€èŠå¤©
const response = await agent.chat('ä½ å¥½');

// ç³»ç»Ÿæç¤ºè¯èŠå¤©
const response = await agent.chatWithSystem('ä½ æ˜¯ä»£ç åŠ©æ‰‹', 'å†™ä¸ªæ’åº');

// å¤šè½®å¯¹è¯
const messages = [
  { role: 'user', content: 'ä½ å¥½' },
  { role: 'assistant', content: 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ' },
  { role: 'user', content: 'å†é—®ä¸€ä¸ªé—®é¢˜' }
];
const response = await agent.conversation(messages);

// è·å–é…ç½®
const config = agent.getConfig();

// æ›´æ–°é…ç½®
agent.updateConfig({ modelName: 'new-model' });
```

### `LLMManager` - LLMè°ƒç”¨ç®¡ç†å™¨

```typescript
import { LLMManager } from 'blade-ai';

// åˆ›å»ºLLMç®¡ç†å™¨
const llm = new LLMManager({
  apiKey: 'sk-xxx',
  baseUrl: 'https://api.example.com',
  modelName: 'my-model'
});

// åŸºç¡€è°ƒç”¨
const response = await llm.send({
  messages: [{ role: 'user', content: 'ä½ å¥½' }]
});

// å¿«é€ŸèŠå¤©
const response = await llm.chat('ä½ å¥½');

// ç³»ç»Ÿå¯¹è¯
const response = await llm.chatWithSystem('ä½ æ˜¯ä»£ç åŠ©æ‰‹', 'å†™ä¸ªæ’åº');

// å¤šè½®å¯¹è¯
const response = await llm.conversation(messages);

// æ›´æ–°é…ç½®
llm.configure({ modelName: 'new-model' });
```

## ğŸ› ï¸ é…ç½®ç®¡ç†

### `ConfigManager` - é…ç½®ç®¡ç†å™¨

```typescript
import { ConfigManager } from 'blade-ai';

// åˆ›å»ºé…ç½®ç®¡ç†å™¨
const config = new ConfigManager();

// è·å–å®Œæ•´é…ç½®
const settings = config.getConfig();

// è·å–ç‰¹å®šé…ç½®é¡¹
const apiKey = config.get('apiKey');

// è®¾ç½®é…ç½®é¡¹
config.set('modelName', 'new-model');

// æ›´æ–°é…ç½®
config.updateConfig({ baseUrl: 'https://new-api.com' });
```

## ğŸ“‹ ç±»å‹å®šä¹‰

### `BladeConfig` - å¹³é“ºé…ç½®æ¥å£

```typescript
interface BladeConfig {
  // è®¤è¯é…ç½®ï¼ˆå¿…éœ€ï¼‰
  apiKey: string;
  baseUrl?: string;
  modelName?: string;
  searchApiKey?: string;

  // UIé…ç½®  
  theme?: 'GitHub' | 'dark' | 'light' | 'auto';
  hideTips?: boolean;
  hideBanner?: boolean;

  // å®‰å…¨é…ç½®
  sandbox?: 'docker' | 'none';
  
  // å·¥å…·é…ç½®
  toolDiscoveryCommand?: string;
  toolCallCommand?: string;
  summarizeToolOutput?: Record<string, { tokenBudget?: number }>;

  // MCPé…ç½®
  mcpServers?: Record<string, {
    command: string;
    args?: string[];
    env?: Record<string, string>;
  }>;

  // é¥æµ‹é…ç½®
  telemetry?: {
    enabled?: boolean;
    target?: 'local' | 'remote';
    otlpEndpoint?: string;
    logPrompts?: boolean;
  };

  // ä½¿ç”¨é…ç½®
  usageStatisticsEnabled?: boolean;
  maxSessionTurns?: number;

  // è°ƒè¯•é…ç½®
  debug?: boolean;
}
```

### `LLMMessage` - æ¶ˆæ¯æ¥å£

```typescript
interface LLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}
```

### `LLMRequest` - è¯·æ±‚æ¥å£

```typescript
interface LLMRequest {
  messages: LLMMessage[];
  apiKey: string;
  baseUrl: string;
  modelName: string;
  temperature?: number;
  maxTokens?: number;
  stream?: boolean;
  timeout?: number;
}
```

### `LLMResponse` - å“åº”æ¥å£

```typescript
interface LLMResponse {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  model?: string;
}
```

## ğŸ”„ é…ç½®åŠ è½½é¡ºåº

```javascript
// 1. é»˜è®¤é…ç½®
const DEFAULT_CONFIG = {
  apiKey: '',
  baseUrl: 'https://apis.iflow.cn/v1',
  modelName: 'Qwen3-Coder',
  // ... å…¶ä»–é»˜è®¤å€¼
};

// 2. ç”¨æˆ·é…ç½® (~/.blade/config.json)
// 3. é¡¹ç›®é…ç½® (./.blade.json æˆ– package.json#blade)
// 4. ç¯å¢ƒå˜é‡ (BLADE_*)
// 5. CLIå‚æ•° (--api-key ç­‰)
```